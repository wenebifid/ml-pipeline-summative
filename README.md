# ML Pipeline â€“ Summative Project

## ğŸ“Œ Project Overview

This project demonstrates an endâ€‘toâ€‘end **Machine Learning Pipeline** that covers data preparation, model training, API deployment, and system testing under load. The system exposes prediction endpoints via an API and includes a userâ€‘facing interface for interaction. A flood request (stress) simulation was conducted to evaluate performance, stability, and scalability.

The project is designed to showcase:

* Clean ML pipeline structure
* Model retraining capability
* APIâ€‘based predictions
* Frontend interaction
* System behaviour under high request volume

---

## ğŸ¥ Video Demo

A full walkthrough of the project (architecture, setup, training, API usage, and flood simulation results) is available here:

**YouTube Demo:** 

---

## ğŸŒ Application URLs

> Replace these with your deployed URLs if applicable.

* **API Base URL:** https://ml-pipeline-summative-1d62.onrender.com/docs

* **Frontend** https://ml-pipeline-summative-1d62.onrender.com

If running locally, URLs will be provided in the terminal during startup.

---

## ğŸ—‚ï¸ Repository Structure (High Level)

```
ml-pipeline-summative/
â”‚
â”œâ”€â”€ data/                  # Training and testing datasets
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ src/                   # Core ML logic
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ prediction.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ charts.py
â”‚
â”œâ”€â”€ api/                   # FastAPI application
â”‚
â”œâ”€â”€ streamlit_app.py       # Frontend interface
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ README.md
â””â”€â”€ tests/                 # Load / flood simulation scripts
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/ml-pipeline-summative.git
cd ml-pipeline-summative
```

---

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv venv
```

**Windows**

```bash
venv\Scripts\activate
```

**macOS / Linux**

```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Prepare Dataset

Ensure the dataset is structured as follows:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ class_1/
â”‚   â”œâ”€â”€ class_2/
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â”œâ”€â”€ class_1/
    â”œâ”€â”€ class_2/
    â””â”€â”€ ...
```

> Each class is split **80% for training** and **20% for testing**.

---

### 5ï¸âƒ£ Train or Retrain the Model

```bash
python src/model.py
```

This will:

* Load the training data
* Train the model
* Save the trained model for inference

---

### 6ï¸âƒ£ Start the API Server

```bash
uvicorn api.main:app --reload
```

API will be available at:

```
http://127.0.0.1:8000
```

Swagger Docs:

```
http://127.0.0.1:8000/docs
```

---

### 7ï¸âƒ£ Run the Streamlit Frontend

```bash
streamlit run streamlit_app.py
```

---

## ğŸ” Flood Request Simulation

A flood (stress) test was conducted to simulate a large number of concurrent prediction requests to the API.

### ğŸ”§ Tool Used

* Custom Python script / load testing tool (e.g. asyncio / requests / locust)

### ğŸ“Š Simulation Results

<img width="2532" height="1175" alt="Screenshot (115)" src="https://github.com/user-attachments/assets/4db4096a-299a-455a-aa4e-581af27c4f8f" />


### âœ… Observations

* The API remained stable under heavy load
* No crashes or memory leaks observed
* Response times increased slightly but stayed within acceptable limits
* System successfully handled concurrent prediction requests

---

## ğŸ§ª Key Features Demonstrated

* Endâ€‘toâ€‘end ML workflow
* Model retraining support
* REST API integration
* Frontend interaction
* Load and stress testing
* Clear modular code structure

---

## ğŸ“Œ Notes

* This project is intended for academic demonstration purposes
* All components can be deployed locally or on cloud platforms

---

## ğŸ‘¤ Author

**Name:** Oyinwenebi Fiderikumo


---



