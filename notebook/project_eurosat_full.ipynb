{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f2270b",
   "metadata": {},
   "source": [
    "# EuroSAT Image Classification — Full Notebook\n",
    "\n",
    "This notebook demonstrates loading the EuroSAT RGB dataset (via TensorFlow Datasets), preprocessing, transfer-learning training (MobileNetV2), evaluation (accuracy, precision, recall, F1, confusion matrix, ROC AUC, top-3 accuracy), saving the model, prediction on a single image, and retraining with local `data/` folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040cd0ae",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- This notebook assumes you have `tensorflow`, `tensorflow-datasets`, `scikit-learn`, and the `src/` package available (see `requirements.txt`).\n",
    "- You can also replace the TFDS loading with local `data/train` and `data/test` folders if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e2b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and environment checks\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support, roc_auc_score, top_k_accuracy_score\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d72ede",
   "metadata": {},
   "source": [
    "## Load EuroSAT from TFDS (RGB)\n",
    "We split dataset into train/val/test. For quicker runs, reduce the training fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c08d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Eurosat rgb via TFDS\n",
    "(ds_all, ), ds_info = tfds.load('eurosat/rgb', split=['train'], with_info=True, as_supervised=True)\n",
    "print(ds_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ce643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/val/test splits from the single 'train' split\n",
    "total = ds_info.splits['train'].num_examples\n",
    "print(\"Total examples:\", total)\n",
    "\n",
    "# We'll use an 70/20/10 split\n",
    "train_split = 'train[:70%]'\n",
    "val_split = 'train[70%:90%]'\n",
    "test_split = 'train[90%:]'\n",
    "\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load('eurosat/rgb', split=[train_split, val_split, test_split], with_info=True, as_supervised=True)\n",
    "print(ds_info.features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ed888",
   "metadata": {},
   "source": [
    "## Preprocessing: resizing and batching\n",
    "We will preprocess images to 224x224 and use MobileNetV2 preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = preprocess_input(image)\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    return image, label\n",
    "\n",
    "def prepare(ds, shuffle=False):\n",
    "    ds = ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare(ds_train, shuffle=True)\n",
    "val_ds = prepare(ds_val)\n",
    "test_ds = prepare(ds_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f591ed",
   "metadata": {},
   "source": [
    "## Inspect classes and a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a72d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ds_info.features['label'].names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, (img, lbl) in enumerate(ds_train.take(6)):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "    plt.imshow(tf.cast(tf.image.resize(img, (128,128)), tf.uint8))\n",
    "    plt.title(class_names[int(lbl.numpy())])\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1920d",
   "metadata": {},
   "source": [
    "## Build transfer-learning model (MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf38c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "def build_model(num_classes):\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=base.input, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "num_classes = ds_info.features['label'].num_classes\n",
    "model = build_model(num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988896c",
   "metadata": {},
   "source": [
    "## Train (first stage: frozen base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "checkpoint_path = \"models/model_latest.h5\"\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2),\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=8, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352eb127",
   "metadata": {},
   "source": [
    "## Fine-tune (unfreeze some of the base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f391c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze last layers\n",
    "base = model.layers[1]  # MobileNetV2 base (depends on model summary indexing)\n",
    "base.trainable = True\n",
    "\n",
    "# Freeze early layers (optional)\n",
    "for layer in base.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=6, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710772a6",
   "metadata": {},
   "source": [
    "## Evaluation on test set: Accuracy, Precision, Recall, F1, Confusion Matrix, ROC AUC, Top-3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9f96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions and true labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy().tolist())\n",
    "    y_pred.extend(preds.argmax(axis=1).tolist())\n",
    "    y_proba.extend(preds.tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_proba = np.array(y_proba)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix shape:\", cm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-3 accuracy\n",
    "top3 = top_k_accuracy_score(y_true, y_proba, k=3, labels=range(num_classes))\n",
    "print(\"Top-3 accuracy:\", top3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095afeb0",
   "metadata": {},
   "source": [
    "## Save model (already saved by checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab322721",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model saved at', checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23914c30",
   "metadata": {},
   "source": [
    "## Prediction demo: single image from TFDS or local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f6c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a test example from TFDS\n",
    "for img, lbl in ds_test.take(1):\n",
    "    test_img = tf.image.resize(img, IMG_SIZE)\n",
    "    inp = preprocess_input(np.expand_dims(test_img.numpy(), axis=0))\n",
    "    preds = model.predict(inp)\n",
    "    top_idx = preds[0].argsort()[-3:][::-1]\n",
    "    print('Top-3 predictions:')\n",
    "    for idx in top_idx:\n",
    "        print(class_names[idx], preds[0][idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe0613",
   "metadata": {},
   "source": [
    "## Retraining with local `data/train` and `data/test` folders\n",
    "If you have new uploaded images placed into `data/train/<class>` and `data/test/<class>`, you can retrain using the `src.model.train_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938914e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of triggering retrain via src.model using ImageDataGenerator\n",
    "from src.preprocessing import create_generators\n",
    "from src.model import train_model\n",
    "\n",
    "if os.path.exists('data/train') and os.path.exists('data/test'):\n",
    "    print('Local train/test folders found — running retrain for 3 epochs (demo)...')\n",
    "    train_gen, val_gen = create_generators('data/train', 'data/test', batch_size=16)\n",
    "    new_model, new_history = train_model(train_gen, val_gen, out_path='models/model_latest_retrained.h5', epochs=3)\n",
    "    print('Retraining done, model saved to models/model_latest_retrained.h5')\n",
    "else:\n",
    "    print('No local data folders present at data/train and data/test. Place images under these folders to retrain locally.')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}